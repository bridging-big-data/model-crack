{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN + $L_{width}$ - Inspect the Trained Networks\n",
    "\n",
    "Visualize and evaluate the prediction results on Mask R-CNN either a random image or testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import json\n",
    "from PIL import Image, ImageEnhance\n",
    "from skimage import data, img_as_float, exposure\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.morphology import skeletonize\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn_crack import utils\n",
    "from mrcnn_crack import visualize\n",
    "from mrcnn_crack.visualize import display_images\n",
    "import mrcnn_crack.model as modellib\n",
    "from mrcnn_crack.model import log\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update user inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow debugging toggle\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# Import Project script\n",
    "import crack as project\n",
    "\n",
    "WEIGHT_PATH = os.path.join(ROOT_DIR, \"checkpoint/mask_rcnn_crack.h5\")\n",
    "DATA_NAME = \"uavcrack\"\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"dataset/UAVCRACK/test/\")\n",
    "SAVE_DIR = os.path.join(ROOT_DIR, \"results/\"+DATA_NAME)\n",
    "\n",
    "# Set True or False\n",
    "exposure_adjustment = False # True: w/ exposure adjustment          Flase: w/o exposure adjustment\n",
    "single_json = True          # True: create single json per image    False: create one json per dataset (not working)\n",
    "save_image = False          # True: save predicted image            False: do not save predicted image\n",
    "end_point = True            # True: extract end points only         False: extract every boundary points (ref: https://docs.opencv.org/master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = project.Configuration()\n",
    "\n",
    "# Override the training configurations with a few changes for inferencing.\n",
    "class InferenceConfig(config.__class__):\n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device to load the neural network on.\n",
    "# Useful if you're training a model on the same machine, in which case use CPU and leave the GPU for training.\n",
    "DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "# Inspect the model in inference mode\n",
    "TEST_MODE = \"inference\"\n",
    "\n",
    "# Matplotlib axes setup\n",
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Load dataset\"\"\"\n",
    "dataset = project.Datasets()\n",
    "dataset.load_data(DATA_DIR, \"test\")\n",
    "dataset.prepare()\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))\n",
    "\n",
    "# Read image names to be tested\n",
    "file_names = next(os.walk(DATA_DIR))[2]\n",
    "class_names = ['BG', 'crack']\n",
    "\n",
    "fn = file_names\n",
    "file_names = []\n",
    "for f in fn:\n",
    "    if f.lower().endswith(\".jpeg\") or f.lower().endswith(\".jpg\") or f.lower().endswith(\".bmp\"):\n",
    "        file_names.append(f)\n",
    "\n",
    "\n",
    "\"\"\"Load model\"\"\"\n",
    "# Create model in inference mode\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "    \n",
    "\"\"\"Load weight\"\"\"\n",
    "weights_path = WEIGHT_PATH\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create save directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory to save prediction results\n",
    "print(\"Save prediction result to {}\".format(SAVE_DIR))\n",
    "try:  \n",
    "    os.mkdir(SAVE_DIR)\n",
    "except OSError:  \n",
    "    print (\"Creation of the directory %s failed\" % SAVE_DIR)\n",
    "else:  \n",
    "    print (\"Successfully created the directory %s \" % SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize JSON Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each contour point \n",
    "point_dict = {\"x\":0, \"y\":0} #{\"x\":1777.241,\"y\":88.139},{\"x\":1800.574,\"y\":150.139}, ...\n",
    "point_list = []\n",
    "\n",
    "# For each instance crack\n",
    "obj_dict = {}\n",
    "obj_list = []\n",
    "\n",
    "# For each class (set of object)\n",
    "class_dict = {\"objects\":obj_list,\n",
    "             \"classifications\":[]}\n",
    "\n",
    "# For each image\n",
    "img_dict = {\"ID\":\"\",\n",
    "            \"DataRow ID\":\"\",\n",
    "            \"Labeled Data\":\"\",\n",
    "            \"Label\":class_dict,\n",
    "            \"Created By\":\"\",\n",
    "            \"Project Name\":\"Crack Detection\",\n",
    "            \"Created At\":\"\",\n",
    "            \"Updated At\":\"\",\n",
    "            \"Seconds to Label\":\"\",\n",
    "            \"External ID\":\"\",\n",
    "            \"Agreement\":\"\",\n",
    "            \"Benchmark Agreement\":-1,\n",
    "            \"Benchmark ID\":\"\",\n",
    "            \"Dataset Name\":\"\",\n",
    "            \"Reviews\":[],\n",
    "            \"View Label\":\"\",\n",
    "            \"Has Open Issues\":0\n",
    "           }\n",
    "img_list = [] #img_list.append(img_dict)\n",
    "\n",
    "# Final json file\n",
    "result_json = img_list\n",
    "\n",
    "# extract boundary points of crack instances\n",
    "def extract_contours(image, mask, file_name):\n",
    "    crack_mask = np.array(mask).astype(np.uint8)\n",
    "\n",
    "    obj_list = []\n",
    "    img_dict = {\"ID\":\"\",\n",
    "            \"DataRow ID\":\"\",\n",
    "            \"Labeled Data\":\"\",\n",
    "            \"Label\":class_dict,\n",
    "            \"Created By\":\"\",\n",
    "            \"Project Name\":\"Crack Detection\",\n",
    "            \"Created At\":\"\",\n",
    "            \"Updated At\":\"\",\n",
    "            \"Seconds to Label\":\"\",\n",
    "            \"External ID\":\"\",\n",
    "            \"Agreement\":\"\",\n",
    "            \"Benchmark Agreement\":-1,\n",
    "            \"Benchmark ID\":\"\",\n",
    "            \"Dataset Name\":\"\",\n",
    "            \"Reviews\":[],\n",
    "            \"View Label\":\"\",\n",
    "            \"Has Open Issues\":0\n",
    "           }\n",
    "    \n",
    "    for z in range(crack_mask.shape[2]):\n",
    "        _crack_mask = crack_mask[:,:,z].astype(np.uint8)\n",
    "        if end_point: \n",
    "            contours, hierarchy = cv2.findContours(_crack_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        else:\n",
    "            contours, hierarchy = cv2.findContours(_crack_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        cnt = np.array(contours[0]).squeeze().astype(np.int32) #[x,y] -- top-left (0,0)\n",
    "        \n",
    "        if len(cnt.shape) == 1:\n",
    "            cnt = cnt.reshape((cnt.shape[0],1))\n",
    "        \n",
    "        _cnt = np.zeros((cnt.shape[0],cnt.shape[1])).astype(np.int32)    \n",
    "        _cnt[:,0] = cnt[:,0] #image.shape[0] - cnt[:,0] # - image.shape[1]     # axis X\n",
    "        _cnt[:,1] = image.shape[0] - cnt[:,1] #[x,y] -- bottom-left (0,0)       # axis Y\n",
    "        _cnt = _cnt.tolist()\n",
    "                \n",
    "        point_list = []\n",
    "        if len(_cnt) > 1:\n",
    "            for i in range(len(_cnt)):\n",
    "                point_dict = {}\n",
    "                point_dict[\"x\"] = _cnt[i][0]\n",
    "                point_dict[\"y\"] = _cnt[i][1]\n",
    "                point_list.append(point_dict)\n",
    "\n",
    "        obj_dict = {\"featureId\":\"\",\n",
    "            \"schemaId\":\"\",\n",
    "            \"title\":\"Crack\",\n",
    "            \"value\":\"crack\",\n",
    "            \"color\":\"\",\n",
    "            \"polygon\":point_list,\n",
    "            \"instanceURI\":\"\"}\n",
    "        color = \"%03x\" % random.randint(0, 0xFFFFFF)\n",
    "        obj_dict[\"color\"] = \"#\"+color\n",
    "        obj_dict[\"polygon\"] = point_list\n",
    "        obj_list.append(obj_dict)\n",
    "        \n",
    "    class_dict[\"objects\"] = obj_list\n",
    "    img_dict[\"Label\"] = class_dict\n",
    "    img_dict[\"External ID\"] = file_name\n",
    "    \n",
    "    return img_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Run on one random test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(Option 1) Run on one random test image\n",
    "'''\n",
    "\n",
    "class Predict_One_Image:\n",
    "    def __init__(self, save=True, show=True):\n",
    "        self.save = save\n",
    "        self.show = show\n",
    "        self.json = False\n",
    "        self.image_id = \"\"\n",
    "        self.file_name = \"\"\n",
    "        self.true_mask = \"\"\n",
    "        self.pred_mask = \"\"\n",
    "\n",
    "    '''\n",
    "    #### 1-1. Run on original prediction results\n",
    "    '''\n",
    "    def predict_one_random_image(self, image_id):\n",
    "        self.image_id = image_id\n",
    "        \n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset, config, self.image_id, use_mini_mask=False)\n",
    "        info = dataset.image_info[self.image_id]\n",
    "        file_name = info[\"id\"]\n",
    "\n",
    "        if exposure_adjustment:\n",
    "            p2, p98 = np.percentile(image, (0.5, 99.5))\n",
    "            image = exposure.rescale_intensity(image, in_range=(p2, p98))\n",
    "\n",
    "        results = model.detect([image], verbose=0)\n",
    "        r = results[0]\n",
    "\n",
    "        if file_name.endswith(\"jpeg\"):\n",
    "            _file_name = file_name[:-5]\n",
    "        elif file_name.lower().endswith(\".jpg\") or file_name.endswith(\".bmp\"):\n",
    "            _file_name = file_name[:-4]\n",
    "            \n",
    "        \"\"\"Evaluate Accuracy\"\"\"\n",
    "        # Draw precision-recall curve, AP_0.5\n",
    "        AP, precisions, recalls, overlaps = utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                                                  r['rois'], r['class_ids'], r['scores'], r['masks'],\n",
    "                                                  iou_threshold=0.5)\n",
    "        if self.json:\n",
    "            img_list = []\n",
    "            img_dict = {}\n",
    "            img_dict = extract_contours(image, r['masks'], file_name)\n",
    "            img_list.append(img_dict)\n",
    "            result_json = img_list\n",
    "            with open(SAVE_DIR+'/'+_file_name+'.json', 'w') as json_file:\n",
    "                json.dump(result_json, json_file)\n",
    "        \n",
    "        if self.show:\n",
    "            pred_fig = visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'], save=self.save)\n",
    "\n",
    "            if self.save:\n",
    "                pred_fig.savefig(SAVE_DIR+'/'+_file_name+'.png', bbox_inches=\"tight\", figsize=(16,16))\n",
    "\n",
    "        # Update variables\n",
    "        self.file_name = file_name\n",
    "        self.true_mask = gt_mask\n",
    "        self.pred_mask = r['masks']\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    #### 1-2. Run on merged prediction results\n",
    "    '''\n",
    "    def merge_prediction_results(self):\n",
    "\n",
    "        file_name = self.file_name\n",
    "        gt_mask = self.true_mask\n",
    "        r_mask = self.pred_mask\n",
    "        \n",
    "        # 1) Ground-truth mask\n",
    "        if gt_mask.shape[2] > 1:\n",
    "            new_gt_mask = gt_mask[:,:,0]\n",
    "            for i in range(1, gt_mask.shape[2]):\n",
    "                new_gt_mask = new_gt_mask | gt_mask[:,:,i]\n",
    "            new_gt_mask = new_gt_mask.reshape((new_gt_mask.shape[0], new_gt_mask.shape[1], 1))\n",
    "        else:\n",
    "            new_gt_mask = gt_mask\n",
    "\n",
    "        # 2) Prediction mask\n",
    "        if r_mask.size == 0: # check if array is empty (if no instances detected)\n",
    "            new_mask = np.zeros((r_mask.shape[0], r_mask.shape[1], 1)).astype(np.bool)\n",
    "        elif r_mask.shape[2] > 1:\n",
    "            new_mask = r_mask[:,:,0]\n",
    "            if r_mask.shape[2] > 0:\n",
    "                for i in range(1, r_mask.shape[2]):\n",
    "                    new_mask = new_mask | r_mask[:,:,i]\n",
    "                    ### update this to get confidence score instead binary 1\n",
    "            new_mask = new_mask.reshape((new_mask.shape[0], new_mask.shape[1], 1))\n",
    "        else:\n",
    "            new_mask = r_mask\n",
    "\n",
    "\n",
    "        if self.show:\n",
    "            # Visualization\n",
    "            plt.figure(figsize = (24,5))\n",
    "\n",
    "            plt.subplot(141)\n",
    "            plt.title('Ground Truth Mask')\n",
    "            plt.imshow(new_gt_mask.astype(np.int16).squeeze())\n",
    "\n",
    "            plt.subplot(142)\n",
    "            plt.title('Predicted Mask')\n",
    "            plt.imshow(new_mask.astype(np.int16).squeeze())\n",
    "\n",
    "            plt.subplot(143)\n",
    "            plt.title('Pixel-level Confusion Matrix')\n",
    "            #plt.xlabel(\"Predicted\")\n",
    "            #plt.ylabel(\"Actual\")\n",
    "            conf_mat_, precision_, recall_, f_score_ = measure_conf_mat(new_mask, new_gt_mask)\n",
    "            conf_mat_[1][1] = 0 # remove TN\n",
    "            df_cm = pd.DataFrame(conf_mat_, index = [i for i in [\"True\", \"False\"]], columns = [i for i in [\"True\", \"False\"]])\n",
    "            sn.heatmap(df_cm, annot=True, fmt='d')\n",
    "\n",
    "            plt.subplot(144)\n",
    "            Score = []\n",
    "            Metric = []\n",
    "            plt.title('Derivations from Confusion Matrix')\n",
    "            plt.xlabel(\"Metrics\")\n",
    "            plt.ylabel(\"Score\")\n",
    "            Score.append(precision_); Score.append(recall_); Score.append(f_score_);\n",
    "            Metric = [\"Precision\", \"Recall\", \"F-Score\"]\n",
    "            df_score = pd.DataFrame({\"Score\":Score, \"Metric\":Metric})\n",
    "            splot = sn.barplot(x=\"Metric\",y=\"Score\",data=df_score)\n",
    "            splot.set(ylim=(0, 1.0))\n",
    "            for p in splot.patches:\n",
    "                splot.annotate(format(p.get_height(), '.4f'), \n",
    "                               (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                               ha = 'center', va = 'center', \n",
    "                               size=15,\n",
    "                               xytext = (0, -12), \n",
    "                               textcoords = 'offset points')\n",
    "\n",
    "            if self.save:\n",
    "                plt.savefig(os.path.join(SAVE_DIR, os.path.splitext(file_name)[0]+'_eval.png'), dpi=200)\n",
    "            #plt.close('all')\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    #### 1-3. Further Measurements\n",
    "    '''\n",
    "\n",
    "    def measure_width_distribution(self, input_arr):\n",
    "        input_arr = input_arr.astype(np.int16).squeeze()\n",
    "\n",
    "        if len(input_arr.shape) is not 2:\n",
    "            return np.zeros(1).astype(np.float32)\n",
    "            #print(\"shape errors\")\n",
    "\n",
    "        else:\n",
    "            skel = skeletonize(input_arr).astype(np.int16)\n",
    "            edt = distance_transform_edt(input_arr)\n",
    "            dist = edt * skel\n",
    "            dist_nz = dist[np.where(dist > 0)].astype(np.int16)\n",
    "            #hist, bins = np.histogram(dist_nz, bins=(np.max(dist_nz)-np.min(dist_nz)+1))\n",
    "            #hist, bins = np.histogram(dist_nz, bins=256, range=[0,255]) # for range 0-255\n",
    "            hist, bins = np.histogram(dist_nz, bins=np.max(input_arr.shape), range=[0,np.max(input_arr.shape)])\n",
    "            hist_pr = hist/sum(hist)\n",
    "\n",
    "            mu = np.mean(dist_nz)\n",
    "            sigma = np.std(dist_nz)\n",
    "\n",
    "            if self.show:\n",
    "                plt.figure(figsize = (24,5))\n",
    "                plt.subplot(141); plt.title('Original'); plt.imshow(input_arr)\n",
    "                plt.subplot(142); plt.title('Skeletonize'); plt.imshow(skel)\n",
    "                plt.subplot(143); plt.title('EDT'); plt.imshow(edt)\n",
    "                plt.subplot(144); plt.title('Distance Historam'); #plt.hist(dist_nz, range=[np.min(dist_nz)-1,np.max(dist_nz)+1], density=True) #plt.imshow(dist.astype(np.int16).squeeze())\n",
    "                df_hist = pd.DataFrame({\"Probability\":hist_pr, \"Width\":np.arange(0,np.max(input_arr.shape))})\n",
    "                splot = sn.barplot(x=\"Width\", y=\"Probability\", data=df_hist); splot.set(ylim=(0, 1.0)); splot.set(xlim=(0,np.max(dist_nz)+1))\n",
    "                for p in splot.patches:\n",
    "                    if p.get_height() > 0:\n",
    "                        splot.annotate(format(p.get_height(), '.4f'), \n",
    "                                   (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                                   ha = 'center', va = 'center', \n",
    "                                   size=10,\n",
    "                                   xytext = (0, 12), \n",
    "                                   textcoords = 'offset points')\n",
    "                plt.text(x=np.max(dist_nz)/10, y=0.9, s=\"Mean: \" + str(np.around(mu,4)))\n",
    "                plt.text(x=np.max(dist_nz)/10, y=0.8, s=\"Std. dev: \" + str(np.around(sigma,4)))\n",
    "\n",
    "        return dist, hist_pr, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mypred = Predict_One_Image(save=True, show=True)\n",
    "\n",
    "random_idx = random.choices(dataset.image_ids, k=1)\n",
    "for d in tqdm(random_idx):\n",
    "    mypred.predict_one_random_image(d)\n",
    "    _,_,mu1,sigma1 = mypred.measure_width_distribution(mypred.true_mask)\n",
    "    _,_,mu2,sigma2 = mypred.measure_width_distribution(mypred.pred_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Run on all test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "(Option 2) Run on all test images\n",
    "'''\n",
    "\n",
    "if single_json == False:\n",
    "    img_list = []\n",
    "for idx,file_name in enumerate(tqdm(file_names)):   \n",
    "    \n",
    "    image = cv2.imread(os.path.join(DATA_DIR, file_name))\n",
    "\n",
    "    if exposure_adjustment:\n",
    "        p2, p98 = np.percentile(image, (0.5, 99.5))\n",
    "        image = exposure.rescale_intensity(image, in_range=(p2, p98))\n",
    "    \n",
    "    # Run detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "\n",
    "    # Visualize results\n",
    "    r = results[0]\n",
    "    fig = visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'], save=save_image)\n",
    "    \n",
    "    if file_name.endswith(\"jpeg\"):\n",
    "        _file_name = file_name[:-5]\n",
    "    elif file_name.lower().endswith(\".jpg\") or file_name.endswith(\".bmp\"):\n",
    "        _file_name = file_name[:-4]\n",
    "    \n",
    "    # Merge masks if needed\n",
    "    if r['masks'].shape[2] > 1:\n",
    "        new_mask = r['masks'][:,:,0]\n",
    "        for i in range(1, r['masks'].shape[2]):\n",
    "            new_mask = new_mask | r['masks'][:,:,i]\n",
    "        new_mask = new_mask.reshape((new_mask.shape[0], new_mask.shape[1], 1))\n",
    "    elif r['masks'].shape[2] == 0:\n",
    "        new_mask = np.zeros((r['masks'].shape[0],r['masks'].shape[1],1))\n",
    "    else:\n",
    "        new_mask = r['masks']\n",
    "    \n",
    "    # Save predicted images\n",
    "    cv2.imwrite(SAVE_DIR+'/'+_file_name+'_pred.jpg', new_mask.astype(np.int16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pixel-level confusion matrix on single dimension masks (merged masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_conf_mat(mask, gt_mask):\n",
    "    TP = TN = FP = FN = err = 0\n",
    "    \n",
    "    for x in range(mask.shape[0]):\n",
    "        for y in range(mask.shape[1]):\n",
    "            if gt_mask[x][y] == True and mask[x][y] == True:\n",
    "                TP += 1\n",
    "            elif gt_mask[x][y] == False and mask[x][y] == True:\n",
    "                FP += 1\n",
    "            elif gt_mask[x][y] == True and mask[x][y] == False:\n",
    "                FN += 1\n",
    "            elif gt_mask[x][y] == False and mask[x][y] == False:\n",
    "                TN += 1\n",
    "            else:\n",
    "                err += 1\n",
    "                \n",
    "    if err > 0:\n",
    "        print(\"error pixels: {}\".format(err))\n",
    "    \n",
    "    conf_mat = np.array([[TP, FN], [FP, TN]])\n",
    "    \n",
    "    if TP == 0:\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        f_score = 0\n",
    "    else:\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f_score = 2*precision*recall / (precision+recall)\n",
    "    \n",
    "    return conf_mat, precision, recall, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conf_mat = np.zeros((2,2)).astype(np.int16)\n",
    "conf_mat_norm = np.zeros((2,2)).astype(np.int16)\n",
    "img_count = 0\n",
    "Precision = []\n",
    "Recall = []\n",
    "FScore = []\n",
    "\n",
    "for i in tqdm(range(len(file_names))):\n",
    "    image_id = i\n",
    "    \n",
    "    try:\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask =modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # Run detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    \n",
    "    # Merge instance stacks into one binary mask\n",
    "    # 1) Ground-truth mask\n",
    "    if gt_mask.shape[2] > 1:\n",
    "        new_gt_mask = gt_mask[:,:,0]\n",
    "        for i in range(1, gt_mask.shape[2]):\n",
    "            new_gt_mask = new_gt_mask | gt_mask[:,:,i]\n",
    "        new_gt_mask = new_gt_mask.reshape((new_gt_mask.shape[0], new_gt_mask.shape[1], 1))\n",
    "    else:\n",
    "        new_gt_mask = gt_mask\n",
    "    \n",
    "    # 2) Prediction mask\n",
    "    if r['masks'].size == 0: # check if array is empty (if no instances detected)\n",
    "        new_mask = np.zeros((r['masks'].shape[0], r['masks'].shape[1], 1)).astype(np.bool)\n",
    "    elif r['masks'].shape[2] > 1:\n",
    "        new_mask = r['masks'][:,:,0]\n",
    "        if r['masks'].shape[2] > 0:\n",
    "            for i in range(1, r['masks'].shape[2]):\n",
    "                new_mask = new_mask | r['masks'][:,:,i]\n",
    "        new_mask = new_mask.reshape((new_mask.shape[0], new_mask.shape[1], 1))\n",
    "    else:\n",
    "        new_mask = r['masks']\n",
    "    \n",
    "    # Measure confusion matrix\n",
    "    conf_mat_, precision_, recall_, f_score_ = measure_conf_mat(new_mask, new_gt_mask)\n",
    "    conf_mat = conf_mat + conf_mat_\n",
    "    Precision.append(precision_)\n",
    "    Recall.append(recall_)\n",
    "    FScore.append(f_score_)\n",
    "    img_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "model_name = os.path.split(os.path.split(weights_path)[0])[1]\n",
    "\n",
    "print(\"Model \\n : {}\".format(model_name))\n",
    "print(\"Average \\n - Precision: {:.4f}\\n - Recall: {:.4f}\\n - F-score: {:.4f}\".format(np.mean(Precision), np.mean(Recall), np.mean(FScore))) \n",
    "\n",
    "np.save(os.path.join(SAVE_DIR, model_name + '_dataset_conf_mat.npy'), conf_mat)\n",
    "np.save(os.path.join(SAVE_DIR, model_name + '_dataset_precision.npy'), Precision)\n",
    "np.save(os.path.join(SAVE_DIR, model_name + '_dataset_recall.npy'), Recall)\n",
    "np.save(os.path.join(SAVE_DIR, model_name + '_dataset_fscore.npy'), FScore)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize = (14,5))\n",
    "plt.subplot(121)\n",
    "plt.title('Pixel-level Confusion Matrix')\n",
    "_conf_mat = conf_mat.copy()\n",
    "_conf_mat[1][1] = 0 # remove TN\n",
    "df_cm = pd.DataFrame(_conf_mat, index = [i for i in [\"True\", \"False\"]], columns = [i for i in [\"True\", \"False\"]])\n",
    "sn.heatmap(df_cm, annot=True, fmt='d')\n",
    "plt.savefig(os.path.join(SAVE_DIR, model_name + '_dataset_conf_mat.png'), dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. AP score based on IoU thresholds (0.5 & 0.75) \n",
    "For instance segmented masks only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get accuracy metrics\"\"\"\n",
    "\n",
    "list_50 = []\n",
    "list_75 = []\n",
    "\n",
    "for i in tqdm(range(len(file_names))):\n",
    "    image_id = i\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
    "\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    \n",
    "    mAP, precisions, recalls, overlaps = utils.compute_ap(gt_bbox, gt_class_id, gt_mask, r['rois'], r['class_ids'], r['scores'], r['masks'], iou_threshold=0.5)\n",
    "    list_50.append([mAP, precisions, recalls])\n",
    "    \n",
    "    mAP, precisions, recalls, overlaps = utils.compute_ap(gt_bbox, gt_class_id, gt_mask, r['rois'], r['class_ids'], r['scores'], r['masks'], iou_threshold=0.75)\n",
    "    list_75.append([mAP, precisions, recalls])\n",
    "\n",
    "print(\"AP@.50: {}\".format( np.mean( np.array(list_50)[:,0] )))\n",
    "print(\"AP@.75: {}\".format( np.mean( np.array(list_75)[:,0] )))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
